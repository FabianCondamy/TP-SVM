{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Compte rendu du TP SVM\"\n",
        "format: html\n",
        "author: \"Fabian Condamy et Samy M'Rad\"\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "L'objectif de ce TP est de se familiariser avec la méthode de classification dite de Support Vector Machine (SVM). Dans la suite, on implémentera cette technique sur différents jeux de données réels et simulés grâce au package scikit-learn de Python. On se concentrera principalement sur la compréhension et la maîtrise des principaux paramètres afin d’en ajuster la flexibilité et d’en évaluer l’impact sur les performances.\n",
        "\n",
        "\n",
        "**Question 1**\n"
      ],
      "id": "1f9bdb8d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "sys.path.append(\"scripts_python\") # pour aller chercher la fonction de svm_source dans le sous dossier\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from svm_source import *\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "X = scaler.fit_transform(X)\n",
        "y = iris.target\n",
        "X = X[y != 0, :2]\n",
        "y = y[y != 0]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "svm_linear = SVC(kernel='linear')\n",
        "svm_linear.fit(X_train, y_train)\n",
        "y_pred_linear = svm_linear.predict(X_test)\n",
        "score_linear = svm_linear.score(X_test, y_test)\n",
        "print('Score du modèle linéaire : %s' % score_linear)\n",
        "\n",
        "def f_linear(xx):\n",
        "    return svm_linear.predict(xx.reshape(1, -1))\n",
        "\n",
        "plt.ion()\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plot_2d(X, y)\n",
        "plt.title(\"iris dataset\")\n",
        "\n",
        "plt.subplot(132)\n",
        "frontiere(f_linear, X, y)\n",
        "plt.title(\"linear kernel\")"
      ],
      "id": "9dc93ab3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour cet aléa précis, on trouve un score de 0,64, ce qui est faible. Comme on peut le voir sur le jeu de données iris, les deux classes sont bien mélangées, ce qui peut expliquer ce score médiocre. \n"
      ],
      "id": "b73fe46f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Définition des hyperparamètres à tester\n",
        "parameters = {'kernel': ['linear'], 'C': list(np.logspace(-3, 3, 200))}\n",
        "\n",
        "# Créer le modèle SVM (ici juste l'objet, le kernel sera défini par GridSearchCV)\n",
        "svm = SVC()\n",
        "\n",
        "# GridSearchCV pour trouver le meilleur C\n",
        "svm_linear_opt = GridSearchCV(svm, parameters, cv=5)  # cv=5 : validation croisée 5 folds\n",
        "svm_linear_opt.fit(X_train, y_train)  # entraîner sur le train set\n",
        "\n",
        "print(\"Score généralisé pour le noyau linéaire : Train : %.3f | Test : %.3f\" %\n",
        "      (svm_linear_opt.score(X_train, y_train),\n",
        "       svm_linear_opt.score(X_test, y_test)))"
      ],
      "id": "35c91d07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour le score généralisé, on trouve une performance de 0,707 pour la partie d'apprentissage et 0,680 pour la partie de test. Ainsi, même en essayant d'optimiser le noyau linéaire, la précision est faible.\n",
        "On va maintenant voir si une méthode polynomiale peut améliorer ce score.\n",
        "\n",
        "**Question 2**\n"
      ],
      "id": "90f1339e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "svm_poly = SVC(kernel='poly')\n",
        "svm_poly.fit(X_train, y_train)\n",
        "y_pred_poly = svm_poly.predict(X_test)\n",
        "score_poly = svm_poly.score(X_test, y_test)\n",
        "print('Score du modèle linéaire : %s' % score_poly)\n",
        "\n",
        "def f_poly(xx):\n",
        "    return svm_poly.predict(xx.reshape(1, -1))\n",
        "\n",
        "plt.ion()\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plot_2d(X, y)\n",
        "plt.title(\"Jeu de données iris\")\n",
        "\n",
        "plt.subplot(132)\n",
        "frontiere(f_poly, X, y)\n",
        "plt.title(\"Noyau polynomial\")"
      ],
      "id": "b5ac6d57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour un noyau polynomial et cet aléa, on trouve un score de 0,6, ce qui est encore plus faible que pour le noyau linéaire. Ce résultat peut sembler assez paradoxal de prime abord, mais il semble en réalité logique au vu de la structure des données, le modèle a dû certainement overfitter.\n"
      ],
      "id": "71161806"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Cs = list(np.logspace(-3, 3, 5))\n",
        "gammas = 10. ** np.arange(-2, 2)  # gamma = [0.01, 0.1, 1, 10]\n",
        "degrees = np.r_[1, 2, 3]\n",
        "\n",
        "parameters = {'kernel': ['poly'], 'C': Cs, 'gamma': gammas, 'degree': degrees}\n",
        "\n",
        "svm = SVC()\n",
        "\n",
        "svm_poly_opt = GridSearchCV(svm, parameters, cv=5)\n",
        "svm_poly_opt.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", svm_poly_opt.best_params_)\n",
        "\n",
        "print(\"Score généralisé pour le noyau polynomial : Train : %.3f | Test : %.3f\" %\n",
        "      (svm_poly_opt.score(X_train, y_train),\n",
        "       svm_poly_opt.score(X_test, y_test)))"
      ],
      "id": "237f58da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour les paramètres généralisés, on trouve un score de 0,707 pour la partie d'apprentissage et 0,64 pour le test. Ainsi, on a le même score généralisé que pour le noyau linéaire pour la partie apprentissage, mais lorsqu'on l'applique à la partie de test, on perd plus en précision que pour le modèle linéaire.\n",
        "\n",
        "Ainsi, ces 2 classes du jeu de données iris semble très difficiles à séparer, la méthode de SVM est peu adaptée ici.\n",
        "\n",
        "**Question 3 (facultative)**\n",
        "\n",
        "Commençons par générer le jeu de données très déséquilibré :\n"
      ],
      "id": "88d42216"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "sys.path.append(\"scripts_python\") # pour aller chercher la fonction de svm_source\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from svm_source import *\n",
        "# Création du jeu de données\n",
        "\n",
        "n = 1000 # nombre d'observations\n",
        "classes = np.random.choice([0,1], size=n, p=[0.9,0.1]) # classes 1 et 2 avec respectivement p=90% et p=10%\n",
        "\n",
        "# Affichage pour vérifier\n",
        "print(np.sort(classes))\n",
        "\n",
        "# Variables pour SVM\n",
        "X = np.random.randn(n, 2)\n",
        "Y = classes\n",
        "\n",
        "def plot_svm(C_value):\n",
        "    clf = SVC(kernel='linear', C=C_value)\n",
        "    clf.fit(X, Y)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(f\"SVM linéaire pour C={C_value}\")\n",
        "\n",
        "    # Tracer les points\n",
        "    plt.scatter(X[Y == 0][:, 0], X[Y == 0][:, 1], label=\"Classe 1 (majoritaire)\", alpha=0.5)\n",
        "    plt.scatter(X[Y == 1][:, 0], X[Y == 1][:, 1], label=\"Classe 2 (minoritaire)\", alpha=0.8)\n",
        "\n",
        "    # Tracer la frontière\n",
        "    ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    xx, yy = np.meshgrid(\n",
        "        np.linspace(xlim[0], xlim[1], 100),\n",
        "        np.linspace(ylim[0], ylim[1], 100)\n",
        "    )\n",
        "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    ax.contour(xx, yy, Z, levels=[0], linewidths=2, linestyles=\"--\", alpha=0.7)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Afficher plusieurs valeurs de C\n",
        "for C in [1, 0.1, 0.01]:\n",
        "    plot_svm(C)"
      ],
      "id": "3bb86bf0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sur un jeu de données purement aléatoire, on observe que le paramètre C n'a aucune influence, les frontières n'apparaissent même pas. Ceci est logique car les données sont impossibles à séparer facilement, il n'y a aucune logique sous-jacente à cette répartition des points.\n",
        "\n",
        "Si on prend maintenant un jeu de données plus structuré :\n"
      ],
      "id": "923192de"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Génération d'un dataset structuré (mais déséquilibré)\n",
        "n_majoritaire = 90\n",
        "n_minoritaire = 10\n",
        "\n",
        "# Classe majoritaire centrée en (0,0)\n",
        "X_majoritaire = np.random.randn(n_majoritaire, 2) * 0.8 + np.array([0, 0])\n",
        "# Classe minoritaire centrée en (3,3)\n",
        "X_minoritaire = np.random.randn(n_minoritaire, 2) * 0.8 + np.array([3, 3])\n",
        "\n",
        "X = np.vstack((X_majoritaire, X_minoritaire))\n",
        "Y = np.array([0]*n_majoritaire + [1]*n_minoritaire)\n",
        "\n",
        "def plot_svm(C_value):\n",
        "    clf = SVC(kernel='linear', C=C_value)\n",
        "    clf.fit(X, Y)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(f\"SVM linéaire pour C={C_value}\")\n",
        "\n",
        "    # Tracer les points\n",
        "    plt.scatter(X[Y == 0][:, 0], X[Y == 0][:, 1], label=\"Classe 1 (majoritaire)\", alpha=0.5)\n",
        "    plt.scatter(X[Y == 1][:, 0], X[Y == 1][:, 1], label=\"Classe 2 (minoritaire)\", alpha=0.8)\n",
        "\n",
        "    # Tracer la frontière\n",
        "    ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    xx, yy = np.meshgrid(\n",
        "        np.linspace(xlim[0], xlim[1], 100),\n",
        "        np.linspace(ylim[0], ylim[1], 100)\n",
        "    )\n",
        "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    ax.contour(xx, yy, Z, levels=[0], linewidths=2, linestyles=\"--\", alpha=0.7)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Afficher plusieurs valeurs de C\n",
        "for C in [1, 0.1, 0.01]:\n",
        "    plot_svm(C)"
      ],
      "id": "b53d74f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ici, on voit l'action du paramètre C, la frontière se déplace dans les différents exemples. \n",
        "\n",
        "\n",
        "**Question 4**\n"
      ],
      "id": "c390957b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question 7**\n",
        "\n",
        "Le biais introduit par le code se situe dans ces deux lignes :\n"
      ],
      "id": "e986a0d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X -= np.mean(X, axis=0)\n",
        "X /= np.std(X, axis=0)"
      ],
      "id": "7acd1c67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En effet, ici on standardise les données avant de séparer notre jeu de données en 2 pour le train et le test, ce qui fait que l'on utilise à la fois les données du train et du test pour calculer la moyenne et l'écart-type qui vont ensuite être appliqués à l'ensemble de nos données pour les standardiser. Ceci crée un biais car les données de test ne doivent pas servir pour créer le modèle."
      ],
      "id": "86c4cb7f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\Fabian\\anaconda3\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}